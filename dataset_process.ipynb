{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(folder_path):\n",
    "    count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./7segdataset_raw/0 : 262\n",
      "./7segdataset_raw/1 : 222\n",
      "./7segdataset_raw/2 : 236\n",
      "./7segdataset_raw/3 : 204\n",
      "./7segdataset_raw/4 : 184\n",
      "./7segdataset_raw/5 : 198\n",
      "./7segdataset_raw/6 : 200\n",
      "./7segdataset_raw/7 : 158\n",
      "./7segdataset_raw/8 : 190\n",
      "./7segdataset_raw/9 : 177\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\n",
    "    './7segdataset_raw/0', './7segdataset_raw/1', './7segdataset_raw/2', \n",
    "    './7segdataset_raw/3', './7segdataset_raw/4', './7segdataset_raw/5', \n",
    "    './7segdataset_raw/6', './7segdataset_raw/7', './7segdataset_raw/8', './7segdataset_raw/9'\n",
    "]\n",
    "\n",
    "for folder_path in folder_paths: \n",
    "    print(f\"{folder_path} : {count_files(folder_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### augment & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pillow numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import uuid\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, convert=False): \n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    resized_img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    gray_img = resized_img.convert(\"L\")\n",
    "\n",
    "    if convert: \n",
    "        img_array = np.array(gray_img)\n",
    "        noise = np.random.randint(0, 50, img_array.shape, dtype='uint8')\n",
    "        noisy_img_array = np.clip(img_array+noise, 0, 255)\n",
    "        noisy_img = Image.fromarray(noisy_img_array)\n",
    "    \n",
    "        rotated_img = noisy_img.rotate(np.random.randint(0, 15))\n",
    "\n",
    "        return rotated_img\n",
    "    \n",
    "    return gray_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(folder_path, dest_count, dest_folder_path): \n",
    "    dest_folder_path = os.path.join(dest_folder_path, os.path.basename(folder_path))\n",
    "    os.makedirs(dest_folder_path, exist_ok=True) \n",
    "\n",
    "    image_extensions = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\"}\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(tuple(image_extensions))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        processed_img = process_image(os.path.join(folder_path, image_file), convert=False)\n",
    "        output_name = str(uuid.uuid4())+'.jpg'\n",
    "        processed_img.save(os.path.join(dest_folder_path, output_name))\n",
    "\n",
    "    aug_count = dest_count - len(image_files) if dest_count > len(image_files) else 0 \n",
    "    for _ in range(aug_count): \n",
    "        image_file = random.choice(image_files)\n",
    "        processed_img = process_image(os.path.join(folder_path, image_file), convert=True)\n",
    "        output_name = str(uuid.uuid4())+'.jpg'\n",
    "        processed_img.save(os.path.join(dest_folder_path, output_name))\n",
    "    \n",
    "    print(f\"from {folder_path} to {dest_folder_path}, augmented {dest_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from ./7segdataset_raw/0 to ./7segdataset_aug/0, augmented 300 images\n",
      "from ./7segdataset_raw/1 to ./7segdataset_aug/1, augmented 300 images\n",
      "from ./7segdataset_raw/2 to ./7segdataset_aug/2, augmented 300 images\n",
      "from ./7segdataset_raw/3 to ./7segdataset_aug/3, augmented 300 images\n",
      "from ./7segdataset_raw/4 to ./7segdataset_aug/4, augmented 300 images\n",
      "from ./7segdataset_raw/5 to ./7segdataset_aug/5, augmented 300 images\n",
      "from ./7segdataset_raw/6 to ./7segdataset_aug/6, augmented 300 images\n",
      "from ./7segdataset_raw/7 to ./7segdataset_aug/7, augmented 300 images\n",
      "from ./7segdataset_raw/8 to ./7segdataset_aug/8, augmented 300 images\n",
      "from ./7segdataset_raw/9 to ./7segdataset_aug/9, augmented 300 images\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\n",
    "    './7segdataset_raw/0', './7segdataset_raw/1', './7segdataset_raw/2', \n",
    "    './7segdataset_raw/3', './7segdataset_raw/4', './7segdataset_raw/5', \n",
    "    './7segdataset_raw/6', './7segdataset_raw/7', './7segdataset_raw/8', './7segdataset_raw/9'\n",
    "]\n",
    "output_folder = './7segdataset_aug'\n",
    "\n",
    "for folder_path in folder_paths: \n",
    "    augment(folder_path, dest_count=300, dest_folder_path=output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./7segdataset_aug/0 : 300\n",
      "./7segdataset_aug/1 : 300\n",
      "./7segdataset_aug/2 : 300\n",
      "./7segdataset_aug/3 : 300\n",
      "./7segdataset_aug/4 : 300\n",
      "./7segdataset_aug/5 : 300\n",
      "./7segdataset_aug/6 : 300\n",
      "./7segdataset_aug/7 : 300\n",
      "./7segdataset_aug/8 : 300\n",
      "./7segdataset_aug/9 : 300\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\n",
    "    './7segdataset_aug/0', './7segdataset_aug/1', './7segdataset_aug/2', \n",
    "    './7segdataset_aug/3', './7segdataset_aug/4', './7segdataset_aug/5', \n",
    "    './7segdataset_aug/6', './7segdataset_aug/7', './7segdataset_aug/8', './7segdataset_aug/9'\n",
    "]\n",
    "\n",
    "for folder_path in folder_paths: \n",
    "    print(f\"{folder_path} : {count_files(folder_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(root_folder_path, dest_folder_path, split_rate=(0.7, 0.2, 0.1)):     \n",
    "    assert round(sum([r for r in split_rate])) == 1 , \"total sum of split rates should be 1(100%).\"\n",
    "\n",
    "    os.makedirs(dest_folder_path, exist_ok=True)\n",
    "\n",
    "    class_folders = [f for f in os.listdir(root_folder_path) if os.path.isdir(os.path.join(root_folder_path, f))]\n",
    "\n",
    "    for class_folder in class_folders: \n",
    "        image_extensions = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\"}\n",
    "        folder_path = os.path.join(root_folder_path, class_folder)\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(tuple(image_extensions))]\n",
    "        random.shuffle(image_files)\n",
    "        \n",
    "        total =  len(image_files)\n",
    "        train_size = int(total * split_rate[0])\n",
    "        val_size = int(total * split_rate[1])\n",
    "        test_size = total - train_size - val_size\n",
    "\n",
    "        train_set = image_files[:train_size]\n",
    "        val_set = image_files[train_size:train_size + val_size]\n",
    "        test_set = image_files[train_size + val_size:]\n",
    "\n",
    "        train_class_folder = os.path.join(dest_folder_path, 'train', class_folder)\n",
    "        val_class_folder = os.path.join(dest_folder_path, 'val', class_folder)\n",
    "        test_class_folder = os.path.join(dest_folder_path, 'test', class_folder)\n",
    "        os.makedirs(train_class_folder, exist_ok=True)\n",
    "        os.makedirs(val_class_folder, exist_ok=True)\n",
    "        os.makedirs(test_class_folder, exist_ok=True)\n",
    "\n",
    "        for train_img in train_set: \n",
    "            shutil.copy(os.path.join(folder_path, train_img), os.path.join(train_class_folder, train_img))\n",
    "        for val_img in val_set: \n",
    "            shutil.copy(os.path.join(folder_path, val_img), os.path.join(val_class_folder, val_img))\n",
    "        for test_img in test_set: \n",
    "            shutil.copy(os.path.join(folder_path, test_img), os.path.join(test_class_folder, test_img))\n",
    "\n",
    "        print(f\"from {folder_path} to {dest_folder_path}, {total} copied with split (train,val,test)={split_rate}\" )                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from ./7segdataset_aug/9 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/0 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/7 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/6 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/1 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/8 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/4 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/3 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/2 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n",
      "from ./7segdataset_aug/5 to ./7segdataset_aug_split, 300 copied with split (train,val,test)=(0.7, 0.2, 0.1)\n"
     ]
    }
   ],
   "source": [
    "root_folder_path = './7segdataset_aug'\n",
    "dest_folder_path = './7segdataset_aug_split'\n",
    "\n",
    "split(root_folder_path, dest_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./7segdataset_aug_split/train/0 : 210\n",
      "./7segdataset_aug_split/val/0 : 60\n",
      "./7segdataset_aug_split/test/0 : 30\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\n",
    "    './7segdataset_aug_split/train/0', './7segdataset_aug_split/val/0', './7segdataset_aug_split/test/0', \n",
    "]\n",
    "\n",
    "for folder_path in folder_paths: \n",
    "    print(f\"{folder_path} : {count_files(folder_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
